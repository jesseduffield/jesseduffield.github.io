---
layout: post
title: "Are AI agents cognitive Ozempic?"
---

Ozempic is an equaliser. There's only so far you can go in the direction of a healthy weight. If you were overweight, Ozempic is great news. But if you were already at a healthy weight? Well, now you're less special. That's what equalisers do: they compress the range of outcomes.

Substack is an amplifier.

Once upon a time, if you wanted to make a living as a writer, you had to convince an editor to hire you. That gatekeeping was unfair, but more importantly, it also compressed outcomes! A mediocre staff writer at the New York Times earned roughly the same salary as a brilliant one.

Then Substack removed the gate entirely. A small number of writers with existing audiences and distinctive voices now earn seven figures. The long tail earns nothing. Access has been equalised (you can go and make a Substack right now!) but _outcomes_ have been amplified (nobody's going to read your Substack).

The equalise-access, amplify-outcomes pattern is common to technology: the internet did it with music distribution, online courses did it with education, and Shopify did it to entrepreneurship. Every time, the gatekeepers are removed, the barrier to entry is reduced, but the underlying distribution of talent remains the same and is now exposed.

So why do some technologies equalise outcomes and others amplify?

I think it comes down to ceilings. Equalisers have a _ceiling_: there's a maximum benefit, and once you hit it, the tool stops helping. Ozempic gets you to a healthy weight and then it's done. Robot vacuum cleaners don't help the ultra-clean distinguish themselves from slobs because there's only so many rooms in each house to vacuum. A tool that helps you work through a support ticket backlog gets you through that backlog and then it's done. There's nowhere further to go, so outcomes compress.

Amplifiers have no ceiling. The returns to skill keep scaling indefinitely.

Which brings us to agentic AI.

Joe Blow can now build a fully deployed website with a single prompt. Access: equalised. But can Mr Blow build a software product with two million lines of code and thousands of paying customers, each pushing for conflicting features? I've been vibe-coding with Opus 4.6 and it is genuinely some next-level sci-fi shit. But once I've told Opus to go off and build me a feature, am I sitting there twiddling my thumbs? No, I'm opening up another tab and spinning up another agent to build another feature. And I continue enlisting agents into my army until I hit the limits of my cognitive ability; the thing which has always been the primary bottleneck in knowledge work.

Right now, AI looks like a classic amplifier. It handles the median-skill parts of knowledge work, and the remaining value accrues to the people with judgment, taste, and vision. Skills that are _less_ evenly distributed than the routine work AI replaces.

But is there a point where this breaks down? What if the waterline keeps rising, the set of things AI can't do keeps shrinking, until one day the gap between a single prompt and a two-million-line codebase closes?

As much as I'd like to proselytise the timeless special-ness of the human mind, I believe that day _will_ come. I have no idea when, but I expect an age of abundance to follow, and I hope that the people who pride themselves on their intelligence don't lose too much self esteem upon finding themselves in a world where intelligence is as much a commodity as water.

Until that day, let's see just how far we can turn the dial on this amplifier.
